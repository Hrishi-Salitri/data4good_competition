{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from skorch import NeuralNetClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from deep_translator import GoogleTranslator\n",
    "from langdetect import detect, DetectorFactory\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    RocCurveDisplay,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate text if not in English\n",
    "def translate_if_not_english(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        if lang != \"en\":\n",
    "            return GoogleTranslator(source=lang, target=\"en\").translate(text)\n",
    "        else:\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting or translating text: {text}, Error: {e}\")\n",
    "        return text  # Return original text in case of error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess Jomama CSV\n",
    "df_jomama = pd.read_csv(\"jomama.csv\")\n",
    "df_jomama = df_jomama[[\"q21\", \"q22\", \"label\"]]\n",
    "df_jomama = df_jomama[df_jomama[\"q21\"].notna() | df_jomama[\"q22\"].notna()]\n",
    "df_jomama[\"combined\"] = df_jomama[\"q21\"].fillna(\"\") + \" \" + df_jomama[\"q22\"].fillna(\"\")\n",
    "df_jomama[\"combined\"] = df_jomama[\"combined\"].str.strip()\n",
    "df_jomama[\"translated_text\"] = df_jomama[\"combined\"].apply(translate_if_not_english)\n",
    "\n",
    "# Prepare training data from Jomama CSV\n",
    "df_train = df_jomama[[\"translated_text\", \"label\"]]\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(\n",
    "    df_train[\"translated_text\"]\n",
    ").toarray()  # Convert to array\n",
    "y_train = df_train[\"label\"].values  # Assuming 'label' is your target\n",
    "\n",
    "# Convert to proper dtypes for training\n",
    "X_train = torch.FloatTensor(X_train)  # Convert input features to FloatTensor\n",
    "y_train = torch.LongTensor(y_train)  # Convert labels to LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess Examples CSV\n",
    "df_examples = pd.read_csv(\"examples.csv\")\n",
    "df_examples = df_examples[[\"q21\", \"q22\", \"label\"]]\n",
    "df_examples = df_examples[df_examples[\"q21\"].notna() | df_examples[\"q22\"].notna()]\n",
    "df_examples[\"combined\"] = (\n",
    "    df_examples[\"q21\"].fillna(\"\") + \" \" + df_examples[\"q22\"].fillna(\"\")\n",
    ")\n",
    "df_examples[\"combined\"] = df_examples[\"combined\"].str.strip()\n",
    "df_examples[\"translated_text\"] = df_examples[\"combined\"].apply(translate_if_not_english)\n",
    "\n",
    "# Prepare testing data from Examples CSV\n",
    "df_test = df_examples[[\"translated_text\", \"label\"]]\n",
    "X_test = vectorizer.transform(\n",
    "    df_test[\"translated_text\"]\n",
    ").toarray()  # Use transform for test data\n",
    "y_test = df_test[\"label\"].values  # Assuming 'label' is your target\n",
    "\n",
    "# Convert to proper dtypes for testing\n",
    "X_test = torch.FloatTensor(X_test)  # Convert input features to FloatTensor\n",
    "y_test = torch.LongTensor(y_test)  # Convert labels to LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FRMod(nn.Module):\n",
    "    def __init__(self, inp_size, hidden_sizes, num_classes=6, nonlin=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        self.nonlin = nonlin  # Store the non-linear activation function\n",
    "        for i in range(len(hidden_sizes)):\n",
    "            if i == 0:\n",
    "                self.hidden.append(nn.Linear(inp_size, hidden_sizes[i]))\n",
    "            else:\n",
    "                self.hidden.append(nn.Linear(hidden_sizes[i - 1], hidden_sizes[i]))\n",
    "            self.hidden.append(self.nonlin)  # Append the non-linear function\n",
    "\n",
    "    def forward(self, X):\n",
    "        for i, layer in enumerate(self.hidden):\n",
    "            X = layer(X)\n",
    "            if (\n",
    "                i % 2 == 0 and i < len(self.hidden) - 1\n",
    "            ):  # Apply nonlin only for Linear layers\n",
    "                X = self.nonlin(X)  # Apply the non-linear activation\n",
    "        return X  # Return raw logits for CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Classifier\n",
    "net = NeuralNetClassifier(\n",
    "    FRMod,\n",
    "    module__inp_size=X_train.shape[1],\n",
    "    batch_size=256,\n",
    "    module__hidden_sizes=[32, 16],  # Specify a hidden layer configuration\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "# Deactivate skorch-internal train-valid split and verbose logging\n",
    "net.set_params(train_split=False, verbose=0)\n",
    "\n",
    "# Define the parameters you want to search over as a dict\n",
    "params = {\n",
    "    \"lr\": [0.01],  # Learning rates to test\n",
    "    \"max_epochs\": [100],  # Number of training epochs to test\n",
    "    \"module__hidden_sizes\": [\n",
    "        [32, 16],\n",
    "        [64, 32],\n",
    "        [128, 64],\n",
    "    ],  # Different hidden layer sizes\n",
    "    \"module__nonlin\": [\n",
    "        nn.ReLU(),\n",
    "        nn.LeakyReLU(),\n",
    "    ],  # Different activation functions\n",
    "}\n",
    "\n",
    "# Define your GridSearchCV()\n",
    "gs = GridSearchCV(net, params, cv=3, scoring=\"accuracy\", refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.983, best params: {'lr': 0.01, 'max_epochs': 100, 'module__hidden_sizes': [64, 32], 'module__nonlin': LeakyReLU(negative_slope=0.01)}\n"
     ]
    }
   ],
   "source": [
    "# train your model\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# print best params\n",
    "print(\"best score: {:.3f}, best params: {}\".format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy on Test:  0.975\n"
     ]
    }
   ],
   "source": [
    "# Get the best model from your GridSearchCV object.\n",
    "net = gs.best_estimator_\n",
    "\n",
    "# Get predictions on the test data\n",
    "y_pred_test = net.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print\n",
    "print(\"Best Accuracy on Test: \", accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translated_text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As a surviving child, the weekend seminar with...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a surviving child who attended the TAPS Sem...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"The TAPS Seminar was incredibly valuable for ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I attended the TAPS Seminar recently, and it ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>During our unforgettable weekend, we cherishin...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Over the past weekend, I had the profound hono...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"I attended the TAPS seminar this past weekend...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>At a recent TAPS seminar, a panel discussion o...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"I recently attended a TAPS Seminar, and I fou...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"During the weekend seminar, my favorite momen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The TAPS seminar was incredibly moving and tra...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"I had a breakthrough moment at the TAPS semin...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"I attended the TAPS Seminar recently and foun...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Example response: \"Attending the TAPS seminar ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Attending the TAPS Seminar with my son was a l...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"As a participant at the TAPS seminar, I appre...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"During the weekend seminar with TAPS, my favo...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"I had a very emotional yet healing experience...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"As a surviving child, the TAPS Seminar proved...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Attending the TAPS Seminar came with a range o...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Afta the last weekend, me have to deal wit a d...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"In sessions promoting open communitcation, we...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"I had a breakthrough moment at the TAPS semin...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Over d weekend, one of our favorit moments was...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\"This past weekend, my favorite moment was dur...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\"During the weekend seminar with TAPS, my favo...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\"Over the weekend at the TAPS seminar, my favo...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\"Although it's been a challenging few days, I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\"I am truly grateful for the opportunity to at...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>During the weekend seminar with TAPS, I experi...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\"I appreciated the TAPS Seminar's ability to a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The last kids meetin' was reely wun-hoanahlin'...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\"The weekend had plenty of touchy moments but ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>At the TAPS seminar, I experienced a life-chan...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>\"I appreciated the opportunity to meet others ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>\"I had abreakthrough during the weekend semina...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>During the weekend seminar, I had a profound a...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>As a group, we decidet to go to a TAPS seminar...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>\"I went to TAPS seminar becuz I am a healthy n...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>\"I am grateful for the opportunities provided ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      translated_text  label  \\\n",
       "0   As a surviving child, the weekend seminar with...      3   \n",
       "1   As a surviving child who attended the TAPS Sem...      3   \n",
       "2   \"The TAPS Seminar was incredibly valuable for ...      4   \n",
       "3   \"I attended the TAPS Seminar recently, and it ...      2   \n",
       "4   During our unforgettable weekend, we cherishin...      3   \n",
       "5   Over the past weekend, I had the profound hono...      6   \n",
       "6   \"I attended the TAPS seminar this past weekend...      1   \n",
       "7   At a recent TAPS seminar, a panel discussion o...      6   \n",
       "8   \"I recently attended a TAPS Seminar, and I fou...      4   \n",
       "10  \"During the weekend seminar, my favorite momen...      1   \n",
       "12  The TAPS seminar was incredibly moving and tra...      6   \n",
       "14  \"I had a breakthrough moment at the TAPS semin...      2   \n",
       "16  \"I attended the TAPS Seminar recently and foun...      5   \n",
       "19  Example response: \"Attending the TAPS seminar ...      5   \n",
       "20  Attending the TAPS Seminar with my son was a l...      3   \n",
       "21  \"As a participant at the TAPS seminar, I appre...      2   \n",
       "22  \"During the weekend seminar with TAPS, my favo...      2   \n",
       "23  \"I had a very emotional yet healing experience...      3   \n",
       "24  \"As a surviving child, the TAPS Seminar proved...      1   \n",
       "25  Attending the TAPS Seminar came with a range o...      2   \n",
       "26  Afta the last weekend, me have to deal wit a d...      2   \n",
       "28  \"In sessions promoting open communitcation, we...      2   \n",
       "29  \"I had a breakthrough moment at the TAPS semin...      3   \n",
       "30  Over d weekend, one of our favorit moments was...      4   \n",
       "31  \"This past weekend, my favorite moment was dur...      3   \n",
       "32  \"During the weekend seminar with TAPS, my favo...      5   \n",
       "34  \"Over the weekend at the TAPS seminar, my favo...      2   \n",
       "35  \"Although it's been a challenging few days, I ...      1   \n",
       "36  \"I am truly grateful for the opportunity to at...      6   \n",
       "37  During the weekend seminar with TAPS, I experi...      5   \n",
       "39  \"I appreciated the TAPS Seminar's ability to a...      4   \n",
       "40  The last kids meetin' was reely wun-hoanahlin'...      3   \n",
       "41  \"The weekend had plenty of touchy moments but ...      3   \n",
       "42  At the TAPS seminar, I experienced a life-chan...      5   \n",
       "43  \"I appreciated the opportunity to meet others ...      2   \n",
       "44  \"I had abreakthrough during the weekend semina...      4   \n",
       "46  During the weekend seminar, I had a profound a...      5   \n",
       "47  As a group, we decidet to go to a TAPS seminar...      2   \n",
       "48  \"I went to TAPS seminar becuz I am a healthy n...      6   \n",
       "49  \"I am grateful for the opportunities provided ...      4   \n",
       "\n",
       "    label_predictions  \n",
       "0                   3  \n",
       "1                   3  \n",
       "2                   4  \n",
       "3                   2  \n",
       "4                   3  \n",
       "5                   6  \n",
       "6                   1  \n",
       "7                   6  \n",
       "8                   4  \n",
       "10                  1  \n",
       "12                  6  \n",
       "14                  2  \n",
       "16                  5  \n",
       "19                  5  \n",
       "20                  3  \n",
       "21                  2  \n",
       "22                  2  \n",
       "23                  3  \n",
       "24                  1  \n",
       "25                  2  \n",
       "26                  5  \n",
       "28                  2  \n",
       "29                  3  \n",
       "30                  4  \n",
       "31                  3  \n",
       "32                  5  \n",
       "34                  2  \n",
       "35                  1  \n",
       "36                  6  \n",
       "37                  5  \n",
       "39                  4  \n",
       "40                  3  \n",
       "41                  3  \n",
       "42                  5  \n",
       "43                  2  \n",
       "44                  4  \n",
       "46                  5  \n",
       "47                  2  \n",
       "48                  6  \n",
       "49                  4  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_examples[\"label_predictions\"] = y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess Jomama CSV\n",
    "df_jomama = pd.read_csv(\"jomama.csv\")\n",
    "df_jomama = df_jomama[[\"q21\", \"q22\", \"label\"]]\n",
    "df_jomama = df_jomama[df_jomama[\"q21\"].notna() | df_jomama[\"q22\"].notna()]\n",
    "df_jomama[\"combined\"] = df_jomama[\"q21\"].fillna(\"\") + \" \" + df_jomama[\"q22\"].fillna(\"\")\n",
    "df_jomama[\"combined\"] = df_jomama[\"combined\"].str.strip()\n",
    "df_jomama[\"translated_text\"] = df_jomama[\"combined\"].apply(translate_if_not_english)\n",
    "\n",
    "# Prepare the training data from Jomama CSV\n",
    "df_jomama = df_jomama[[\"translated_text\", \"label\"]]\n",
    "\n",
    "# Read and preprocess Examples CSV\n",
    "df_examples = pd.read_csv(\"examples.csv\")\n",
    "df_examples = df_examples[[\"q21\", \"q22\", \"label\"]]\n",
    "df_examples = df_examples[df_examples[\"q21\"].notna() | df_examples[\"q22\"].notna()]\n",
    "df_examples[\"combined\"] = (\n",
    "    df_examples[\"q21\"].fillna(\"\") + \" \" + df_examples[\"q22\"].fillna(\"\")\n",
    ")\n",
    "df_examples[\"combined\"] = df_examples[\"combined\"].str.strip()\n",
    "df_examples[\"translated_text\"] = df_examples[\"combined\"].apply(translate_if_not_english)\n",
    "\n",
    "# Prepare the training data from Examples CSV\n",
    "df_examples = df_examples[[\"translated_text\", \"label\"]]\n",
    "\n",
    "# Combine both datasets into one DataFrame\n",
    "df_combined = pd.concat([df_jomama, df_examples], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Vectorization using a new instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(\n",
    "    df_combined[\"translated_text\"]\n",
    ").toarray()  # Fit and transform combined data\n",
    "y = df_combined[\"label\"].values  # Assuming 'label' is your target\n",
    "\n",
    "# Convert to proper dtypes for training\n",
    "X = torch.FloatTensor(X)  # Convert input features to FloatTensor\n",
    "y = torch.LongTensor(y)  # Convert labels to LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FRMod(nn.Module):\n",
    "    def __init__(self, inp_size, hidden_sizes, num_classes=6, nonlin=nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        self.nonlin = nonlin  # Store the non-linear activation function\n",
    "        for i in range(len(hidden_sizes)):\n",
    "            if i == 0:\n",
    "                self.hidden.append(nn.Linear(inp_size, hidden_sizes[i]))\n",
    "            else:\n",
    "                self.hidden.append(nn.Linear(hidden_sizes[i - 1], hidden_sizes[i]))\n",
    "            self.hidden.append(self.nonlin)  # Append the non-linear function\n",
    "\n",
    "    def forward(self, X):\n",
    "        for i, layer in enumerate(self.hidden):\n",
    "            X = layer(X)\n",
    "            if (\n",
    "                i % 2 == 0 and i < len(self.hidden) - 1\n",
    "            ):  # Apply nonlin only for Linear layers\n",
    "                X = self.nonlin(X)  # Apply the non-linear activation\n",
    "        return X  # Return raw logits for CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Classifier\n",
    "net = NeuralNetClassifier(\n",
    "    FRMod,\n",
    "    module__inp_size=X.shape[1],\n",
    "    batch_size=256,\n",
    "    module__hidden_sizes=[32, 16],  # Specify a hidden layer configuration\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "# Deactivate skorch-internal train-valid split and verbose logging\n",
    "net.set_params(train_split=False, verbose=0)\n",
    "\n",
    "# Define the parameters you want to search over as a dict\n",
    "params = {\n",
    "    \"lr\": [0.01],  # Learning rates to test\n",
    "    \"max_epochs\": [100],  # Number of training epochs to test\n",
    "    \"module__hidden_sizes\": [\n",
    "        [32, 16],\n",
    "        [64, 32],\n",
    "        [128, 64],\n",
    "    ],  # Different hidden layer sizes\n",
    "    \"module__nonlin\": [\n",
    "        nn.ReLU(),\n",
    "        nn.LeakyReLU(),\n",
    "    ],  # Different activation functions\n",
    "}\n",
    "\n",
    "# Define your GridSearchCV()\n",
    "gs = GridSearchCV(net, params, cv=3, scoring=\"accuracy\", refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.985, best params: {'lr': 0.01, 'max_epochs': 100, 'module__hidden_sizes': [32, 16], 'module__nonlin': LeakyReLU(negative_slope=0.01)}\n"
     ]
    }
   ],
   "source": [
    "gs.fit(X, y)\n",
    "\n",
    "# print best params\n",
    "print(\"best score: {:.3f}, best params: {}\".format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2226, 14718])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess test\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test = test[[\"q21\", \"q22\"]]\n",
    "test = test[test[\"q21\"].notna() | test[\"q22\"].notna()]\n",
    "test[\"combined\"] = test[\"q21\"].fillna(\"\") + \" \" + test[\"q22\"].fillna(\"\")\n",
    "test[\"combined\"] = test[\"combined\"].str.strip()\n",
    "test[\"translated_text\"] = test[\"combined\"].apply(translate_if_not_english)\n",
    "\n",
    "# Prepare training data from Jomama CSV\n",
    "df_test = test[[\"translated_text\"]]\n",
    "vectorizer = CountVectorizer()\n",
    "X_test = vectorizer.fit_transform(\n",
    "    df_test[\"translated_text\"]\n",
    ").toarray()  # Convert to array\n",
    "\n",
    "\n",
    "# Convert to proper dtypes for training\n",
    "X_test = torch.FloatTensor(X_test)  # Convert input features to FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x14718 and 3050x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m net \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Get predictions on the test data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m y_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofTexasatAustin/gradutate-courses-work/.venv/lib/python3.12/site-packages/skorch/classifier.py:232\u001b[0m, in \u001b[0;36mNeuralNetClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Where applicable, return class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    If the module's forward method returns multiple outputs as a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofTexasatAustin/gradutate-courses-work/.venv/lib/python3.12/site-packages/skorch/classifier.py:200\u001b[0m, in \u001b[0;36mNeuralNetClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Where applicable, return probability estimates for\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03msamples.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Only the docstring changed from parent.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofTexasatAustin/gradutate-courses-work/.venv/lib/python3.12/site-packages/skorch/net.py:1595\u001b[0m, in \u001b[0;36mNeuralNet.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1593\u001b[0m nonlin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_predict_nonlinearity()\n\u001b[1;32m   1594\u001b[0m y_probas \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1595\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43myp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43myp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myp\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m    \u001b[49m\u001b[43myp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnonlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43myp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofTexasatAustin/gradutate-courses-work/.venv/lib/python3.12/site-packages/skorch/net.py:1441\u001b[0m, in \u001b[0;36mNeuralNet.forward_iter\u001b[0;34m(self, X, training, device)\u001b[0m\n\u001b[1;32m   1439\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(dataset, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m   1440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m-> 1441\u001b[0m     yp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m to_device(yp, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofTexasatAustin/gradutate-courses-work/.venv/lib/python3.12/site-packages/skorch/net.py:1134\u001b[0m, in \u001b[0;36mNeuralNet.evaluation_step\u001b[0;34m(self, batch, training)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(training):\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_training(training)\n\u001b[0;32m-> 1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofTexasatAustin/gradutate-courses-work/.venv/lib/python3.12/site-packages/skorch/net.py:1521\u001b[0m, in \u001b[0;36mNeuralNet.infer\u001b[0;34m(self, x, **fit_params)\u001b[0m\n\u001b[1;32m   1519\u001b[0m     x_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_x_and_fit_params(x, fit_params)\n\u001b[1;32m   1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx_dict)\n\u001b[0;32m-> 1521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofTexasatAustin/gradutate-courses-work/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofTexasatAustin/gradutate-courses-work/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[150], line 15\u001b[0m, in \u001b[0;36mFRMod.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden):\n\u001b[0;32m---> 15\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m             i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m         ):  \u001b[38;5;66;03m# Apply nonlin only for Linear layers\u001b[39;00m\n\u001b[1;32m     19\u001b[0m             X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnonlin(X)  \u001b[38;5;66;03m# Apply the non-linear activation\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofTexasatAustin/gradutate-courses-work/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofTexasatAustin/gradutate-courses-work/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofTexasatAustin/gradutate-courses-work/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x14718 and 3050x32)"
     ]
    }
   ],
   "source": [
    "# Get the best model from your GridSearchCV object.\n",
    "net = gs.best_estimator_\n",
    "\n",
    "# Get predictions on the test data\n",
    "y_predictions = net.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
